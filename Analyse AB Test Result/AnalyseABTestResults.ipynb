{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze A/B Test Results for an e-Commerce Website\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression](#regression)\n",
    "- [Conclusion](#conclusion)\n",
    "\n",
    "\n",
    "<a id='intro'></a>\n",
    "### Introduction\n",
    "\n",
    "**A/B tests** are very commonly performed by data analysts and data scientists. It is commonwly used to test changes on a web page by running experiment(s) where a control group sees the old page, while the treatment (experiment) group sees the new page. A metric is chosen to measure the level of engagement from users in each group. The results is used to judge whether one version is more effective than the other.<br>\n",
    "\n",
    "In this project, I analysed the data to understand the results of an A/B test run by an e-commerce website. The *conversion* or *conversion rate* was chosen as the metric for this analysis. The **goal** is:\n",
    "> *to conduct experiment(s) and analyse data to help the company understand if they should implement the new page, keep the old page, or perhaps run the experiment longer to make their decision.*\n",
    "\n",
    "### Analysis Approach\n",
    "This analysis was done systematically using 7-step approach.\n",
    "1. **Understand the datasets**: I reviewed the variables in the datasets\n",
    "2. **State Hypothesis:** Given the goal of this analysis, I stated the null and alternate hypothesis\n",
    "3. **Perform Wrangling:** I read in the data from CSV, assessed and cleaned data set using *pandas* and *numpy* libraries in *Python*\n",
    "4. **Conduct Exploratory Data Analysis (EDA):** Explored the data and created visuals to get clarity of the dataset and maximise the potential of the analysis.*pandas*, *numpy* and *matplotlib* libraries in *Python*. This step was done concurrently with wrangling.\n",
    "5. **Test Hypothesis**: I performed A/B testing (using both the walk-through and built-in method) leveraging *pandas*, *numpy*, *ramdom* and *statsmodels.api*. I also conducted a regression analysis to confirm the result from A/B testing\n",
    "4. **Draw Conclusions:** Intepreted the result from the descriptive and inferential statistical analysis done.\n",
    "5. **Communicate:** Communicated insights in this *Jupyter Notebook*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#set seed to assure that the same answers is gotten each time\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='probability'></a>\n",
    "#### Part I - Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `1.` Read in the `ab_data.csv` data and store it in `df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a. Take a look at the top 5 rows\n",
    "df = pd.read_csv('ab_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294478"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b. Find number of rows in the dataset\n",
    "df.shape[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c. The number of unique users in the dataset\n",
    "df['user_id'].nunique() \n",
    "\n",
    "#Given that this is less than the number of rows,\n",
    "#it signify duplicate users within the datasets that will be addressed later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "d. The proportion of users converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11965919355605512"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d. The proportion of users converted\n",
    "df['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "e. The number of times the `new_page` and `treatment` don't match.\n",
    ">This match is necessary as treatment group are meant to *land* on the new page in this experiment while control group should *land* on the old page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This should be 0. Values != 0 should be noted for cleaning\n",
    "df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       294478 non-null  int64 \n",
      " 1   timestamp     294478 non-null  object\n",
      " 2   group         294478 non-null  object\n",
      " 3   landing_page  294478 non-null  object\n",
      " 4   converted     294478 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "#f. Check for missing values\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `2.` Drop rows with mismatch in `group` and `landing_page` and store it in `df2`\n",
    "\n",
    "These are rows where:\n",
    "1. **treatment** does not match with **new_page** or\n",
    "2. **control** does not match with **old_page**\n",
    "As one cannot be sure if these rows truly received the new or old page.<br>\n",
    "a. Create a new dataset that meets the specifications and store dataframe in df2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where `treatment` does not match with `new_page`\n",
    "df1 = df.drop(df[((df['group'] == 'treatment') == (df['landing_page'] == 'new_page'\n",
    "                                    )) == False].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double Check all of the correct rows were removed - this should be 0\n",
    "df1[((df1['group'] == 'treatment') == (df1['landing_page'] == 'new_page'\n",
    "                                    )) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.query('group == \"treatment\" and landing_page == \"old_page\"')['group'].count() + df.query('group == \"control\" and landing_page != \"old_page\"')['group'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where control does not match with old_page\n",
    "df2 = df1.drop(df1[(df1['group'] == 'control') & (df1['landing_page'] == 'new_page')].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double Check all of the correct rows were removed - this should be 0\n",
    "df2[((df2['group'] == 'control') == (df2['landing_page'] == 'old_page')) == False].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         290585\n",
       "timestamp       290585\n",
       "group           290585\n",
       "landing_page    290585\n",
       "converted       290585\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note new sample size\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `3.` Remove row(s) with duplicate `user_id`  in `df2`\n",
    "\n",
    "Presence of duplicate is indicated by the data showing that count for columns is `290,585` while unique_id is `290,584`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a. Check unique user_ids are in df2\n",
    "df2['user_id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1899</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "1899   773192  2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b. Check for the one user_id repeated in df2\n",
    "df2[df2.duplicated(subset=['user_id'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2893</th>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                   timestamp      group landing_page  converted\n",
       "2893   773192  2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Row information for the repeated user_id\n",
    "df2[df2.duplicated(subset=['user_id'], keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove one of the rows with duplicate user_id and keep dataframe as df2\n",
    "df2 = df2.drop_duplicates(subset=['user_id'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290584 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       290584 non-null  int64 \n",
      " 1   timestamp     290584 non-null  object\n",
      " 2   group         290584 non-null  object\n",
      " 3   landing_page  290584 non-null  object\n",
      " 4   converted     290584 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Double check\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### `4.` Using `df2`, calculate probability\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a. Probability of an individual converting regardless of the page they receive\n",
    "df2['converted'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#b. Probability of conversion in control group\n",
    "control = df2.group == 'control'\n",
    "df2.converted[control].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c. Probability of conversion in treatment group\n",
    "treatment = df2.group == 'treatment'\n",
    "df2.converted[treatment].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d. Probability that an individual received the new page\n",
    "df2['landing_page'][df2['landing_page'] == 'new_page'].count()/df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion based on a. through d. above (Probability)**\n",
    "\n",
    "> **Probability of conversion is 0.119 and 0.120 in the `treatment` and `control` group, respectively. This difference of -0.001 (`treatment` - `control`) is no sufficient evidence to suggest that the new treatment page leads to more conversions.**<br>\n",
    "> Although the sample size seems large enough (>100,000 in each group), one might need to assess the following:\n",
    "> - The duration of experiment- was it run long enough to cover for change aversion and novelty effect.\n",
    "> - The type of participants- if it was new or old clients and the prportion of each in bith groups (treatment and control)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "`1.` Analyse A/B Test Results to make decision based on all the data provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Null and Alternative Hypothesis**\n",
    "\n",
    "$$H_0: p_{new} - p_{old} <= 0$$\n",
    "\n",
    "$$H_0: p_{new} - p_{old} > 0$$\n",
    "\n",
    "$$\\alpha = 0.05$$\n",
    "\n",
    "\n",
    ">$p_{new}$ and $p_{old}$ are the population converted rates for the new and old pages, respectively.<br><br>\n",
    "$\\alpha$ is the Type I error rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`2.` It was assumed under the null hypothesis, $p_{new}$ and $p_{old}$ both have \"true\" success rates equal to the **converted** success rate regardless of page - that is $p_{new}$ and $p_{old}$ are equal. Furthermore, it was assumed that they are equal to the **converted** rate in **ab_data.csv** regardless of the page. A sample size for each page equal to the ones in **ab_data.csv** was used.  <br>\n",
    "Subsequently, the sampling distribution for the difference in **converted** between the two pages over 10,000 iterations of calculating an estimate from the null was performed.  <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. **Conversion rate** for $p_{new}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_new = df2['converted'].mean()\n",
    "cv_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. **Conversion rate** for $p_{old}$ under the null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['converted'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. $n_{new}$ - the number of individuals in the **treatment** group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_new = df2[treatment]['user_id'].count()\n",
    "number_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. $n_{old}$- the number of individuals in the **control** group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2[control]['user_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Simulate $n_{new}$ transactions with a conversion rate of $p_{new}$ under the null.  Store these $n_{new}$ 1's and 0's in **new_page_converted**.\n",
    "\n",
    "> **I noticed that in both cases, the mean changed whenever I ran it...is this normal?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_page_converted = np.random.choice([0,1], size = (number_new,1), p = [(1-cv_new), cv_new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11920033032826371"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Simulate $n_{old}$ transactions with a conversion rate of $p_{old}$ under the null.  Store these $n_{old}$ 1's and 0's in **old_page_converted**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_page_converted = np.random.choice([0,1], size = (145274, 1) , p =[(1-0.11959708724499628),0.11959708724499628])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12007654501149552"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Find $p_{new}$ - $p_{old}$ for simulated values from part (e) and (f)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0008762146832318046"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_page_converted.mean() - old_page_converted.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Create 10,000 $p_{new}$ - $p_{old}$ values using the same simulation process in parts (a) through (g) above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_diffs = []\n",
    "for _ in range (10000):\n",
    "    new_sample = np.random.choice([0,1], size = (145310, 1) , p =[(1-0.11959708724499628),0.11959708724499628])\n",
    "    old_sample = np.random.choice([0,1], size = (145274, 1) , p =[(1-0.11959708724499628),0.11959708724499628])\n",
    "    new_mean = new_sample.mean()\n",
    "    old_mean = old_sample.mean()\n",
    "    p_diffs.append(new_mean - old_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all 10,000 values in a NumPy array called **p_diffs**.\n",
    "p_diffs = np.array(p_diffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Plot a histogram of the **p_diffs**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(p_diffs, alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram **shows a normal distribution centered around 0** as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j. Proportion of the **p_diffs** greater than the actual difference observed in **ab_data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0015782389853555567"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_diffs = df2.converted[treatment].mean() - df2.converted[control].mean()\n",
    "obs_diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_diffs > obs_diffs).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k. **Conclusion based on j. above (A/B Testing)**\n",
    "\n",
    "> In part *j*, I computed the *p-value* = 0.91. This is **not statistically significant**. Therefore, we **fail to reject the null hypothesis**.<br>\n",
    "> Based on these results, there is *no sufficient evidence to suggest that new landing page converts more users than the old landing page.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l. Use a built-in to achieve similar results.<br>\n",
    "In the below:\n",
    " - `convert_old` = number of conversions for old page\n",
    " - `convert_new` = number of conversions for new page\n",
    " - `n_old` = number of rows associated with the old pages\n",
    " - `n_new` = number of rows associated with the new pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_old = df2['group'][(df2['group'] == 'control') & (df2['converted'] == 1)].count()\n",
    "convert_new = df2['group'][(df2['group'] == 'treatment') & (df2['converted'] == 1)].count()\n",
    "n_old = df2[control]['user_id'].count()\n",
    "n_new = df2[treatment]['user_id'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m. Use `stats.proportions_ztest` to compute test statistic and p-value.  [Here](https://docs.w3cub.com/statsmodels/generated/statsmodels.stats.proportion.proportions_ztest/) is a helpful link on using the built in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_score, p_value = sms.stats.proportions_ztest([convert_new, convert_old], [n_new, n_old], alternative='larger')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n. Assess the z-score and p-value computed in m. above and discuss what it means for the conversion rates of the old and new pages.  Do they agree with the findings in parts **j.** and **k.**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inteprete z-score and p-value. (in-built method)** <br>\n",
    "> The negative z-score indicate that the difference observed is lower than mean average by 1.3 standard deviation. This indicates that **the conversion rate is lower on the new page**.<br>\n",
    ">The p-value is **not statistically significant**, therefore we **fail to reject the null hypothesis**. The p-value means that given that the null hypothesis is true, there is a 90.5% chance that the conversion rates we collected for the new page are greater than or equal to those of the old page. <br>\n",
    "The p-value found using the in-built method agrees with the findings in parts j and k**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "### Part III - A Regression Approach\n",
    "1. Perform regression on the dataset<br>\n",
    "a. Type of regression\n",
    "\n",
    "A **Logistic Regression** should be performed since foe each row, conversion is either yes or no conversion (a categorical variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Use **statsmodels** to fit the regression model specified in part **a.** to see if there is a significant difference in conversion based on which page a customer receives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290584 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   user_id       290584 non-null  int64 \n",
      " 1   timestamp     290584 non-null  object\n",
      " 2   group         290584 non-null  object\n",
      " 3   landing_page  290584 non-null  object\n",
      " 4   converted     290584 non-null  int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 13.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#Check dataset\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>old_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  old_page  \n",
       "0          1        0         1  \n",
       "1          1        0         1  \n",
       "2          1        1         0  \n",
       "3          1        1         0  \n",
       "4          1        0         1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create column for intercept\n",
    "#Create dummy variable for landing page (ab_page column = 1 for treatment and 0 for control)\n",
    "#Double check to confirm\n",
    "df2['intercept'] = 1\n",
    "df2[['ab_page', 'old_page']] = pd.get_dummies(df['landing_page'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. Use **statsmodels** to instantiate the regression model on `intercept` and `ab_page` <br>\n",
    "Fit the model using the two columns to predict whether or not an individual converts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 10 Oct 2021</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:11:56</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Sun, 10 Oct 2021   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        18:11:56   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_mod = sms.Logit(df2['converted'], df2[['intercept', 'ab_page']])\n",
    "results = log_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Provide the summary of your model below, and use it as necessary to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.015113064615719"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/np.exp(-0.0150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e. Intepret the p-value associated with **ab_page** in the regression above.\n",
    "\n",
    "> A p-value of 0.19 is associaetd with ab_pages- this is **not statistically significant**. Therefore, we **fail to reject the null hypothesis**. If an individual landed on the new page, they are 1.015 less likely to be converted than than if they landed on the old page, holding all variables constant.\n",
    "> Therefore, there is **no sufficient evidence** to recommend the switch to the new page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f. Other Factors\n",
    "> One might consider adding other factors to the regression model if it influence the outcome. This can lead to significantly increased predictive capacity. However, care has to be taken to ensure that effect of variables influencing eachother is accounted for - such as multicollinearity etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g. Add an effect based on which country a user lives in. Read in the **countries.csv** dataset and merge together datasets on the appropriate rows.  [Here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.join.html) are the docs for joining tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read in countries.csv\n",
    "df_countries = pd.read_csv('countries.csv')\n",
    "df_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the counts and categories of each\n",
    "df_countries['country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  old_page country  \n",
       "0          1        0         1      US  \n",
       "1          1        0         1      US  \n",
       "2          1        1         0      US  \n",
       "3          1        1         0      US  \n",
       "4          1        0         1      US  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Join both datasets \n",
    "df3= df2.join(df_countries.set_index('user_id'), on ='user_id', how ='left' )\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assess dataset\n",
    "df3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>intercept</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>old_page</th>\n",
       "      <th>country</th>\n",
       "      <th>canada</th>\n",
       "      <th>uk</th>\n",
       "      <th>us</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted  \\\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   intercept  ab_page  old_page country  canada  uk  us  \n",
       "0          1        0         1      US       0   0   1  \n",
       "1          1        0         1      US       0   0   1  \n",
       "2          1        1         0      US       0   0   1  \n",
       "3          1        1         0      US       0   0   1  \n",
       "4          1        0         1      US       0   0   1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create dummy variables for country\n",
    "df3[['canada', 'uk', 'us']] = pd.get_dummies(df3['country'])\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    276085\n",
       "1     14499\n",
       "Name: canada, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check\n",
    "df3.canada.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    218118\n",
       "1     72466\n",
       "Name: uk, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check\n",
    "df3.uk.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    203619\n",
       "0     86965\n",
       "Name: us, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Double check\n",
    "df3.us.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 10 Oct 2021</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:11:57</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>canada</th>    <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uk</th>        <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Sun, 10 Oct 2021   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        18:11:57   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "canada        -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "uk             0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the logistic regression model\n",
    "log_mod = sms.Logit(df3['converted'], df3[['intercept', 'ab_page', 'canada', 'uk']])\n",
    "results = log_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intercept    0.136795\n",
       "ab_page      0.985168\n",
       "canada       0.960062\n",
       "uk           1.009932\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00010001000100010001"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Country does not have impact on conversion in my opinion.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h. Though you have now looked at the individual factors of country and page on conversion, we would now like to look at an interaction between page and country to see if there significant effects on conversion.  Create the necessary additional columns, and fit the new model.  \n",
    "\n",
    "Provide the summary results, and your conclusions based on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['ca_new'] = df3['ab_page']*df3['canada']\n",
    "df3['uk_new'] = df3['ab_page']*df3['uk']\n",
    "df3['us_new'] = df3['ab_page']*df3['us']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290577</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     6</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 10 Oct 2021</td> <th>  Pseudo R-squ.:     </th>  <td>3.482e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:11:59</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.2847</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9865</td> <td>    0.010</td> <td> -206.344</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0193</td> <td> 1.53e+05</td> <td>-1.26e-07</td> <td> 1.000</td> <td>-2.99e+05</td> <td> 2.99e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>canada</th>    <td>   -0.0175</td> <td>    0.038</td> <td>   -0.465</td> <td> 0.642</td> <td>   -0.091</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uk</th>        <td>   -0.0057</td> <td>    0.019</td> <td>   -0.306</td> <td> 0.760</td> <td>   -0.043</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ca_new</th>    <td>   -0.0482</td> <td> 1.53e+05</td> <td>-3.15e-07</td> <td> 1.000</td> <td>-2.99e+05</td> <td> 2.99e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>uk_new</th>    <td>    0.0301</td> <td> 1.53e+05</td> <td> 1.97e-07</td> <td> 1.000</td> <td>-2.99e+05</td> <td> 2.99e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>us_new</th>    <td>   -0.0013</td> <td> 1.53e+05</td> <td>-8.32e-09</td> <td> 1.000</td> <td>-2.99e+05</td> <td> 2.99e+05</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290577\n",
       "Method:                           MLE   Df Model:                            6\n",
       "Date:                Sun, 10 Oct 2021   Pseudo R-squ.:               3.482e-05\n",
       "Time:                        18:11:59   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.2847\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9865      0.010   -206.344      0.000      -2.005      -1.968\n",
       "ab_page       -0.0193   1.53e+05  -1.26e-07      1.000   -2.99e+05    2.99e+05\n",
       "canada        -0.0175      0.038     -0.465      0.642      -0.091       0.056\n",
       "uk            -0.0057      0.019     -0.306      0.760      -0.043       0.031\n",
       "ca_new        -0.0482   1.53e+05  -3.15e-07      1.000   -2.99e+05    2.99e+05\n",
       "uk_new         0.0301   1.53e+05   1.97e-07      1.000   -2.99e+05    2.99e+05\n",
       "us_new        -0.0013   1.53e+05  -8.32e-09      1.000   -2.99e+05    2.99e+05\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_mod = sms.Logit(df3['converted'], df3[['intercept', 'ab_page', 'canada', 'uk', 'ca_new', 'uk_new', 'us_new']])\n",
    "results = logit_mod.fit()\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intepretation of Interaction with COuntry of Origin**\n",
    ">The full model with interactions between page and country, indicates that these interactions has no effects on the predictions based on the p-values which are all *not statistically significant* (>0.05). Therefore, it is best to leave these interactions out of the model both practically and statistically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## Conclusion\n",
    "Based on the results of this analysis, the p-value is **not statistically significant** both in the A/B testing and regression. Therefore, there is **no evidence** to suggest that the new page will lead to more conversion than the old-page. Infact, if an individual landed on the new page, they are 1.015 less likely to be converted than than if they landed on the old page, holding all variables constant. This is also supported by result from the probability rate with a difference of -0.001 between the treatment and control group. Furthermore, there was no evidence of that country affects conversion rate.<br>\n",
    "\n",
    "**Limitation:** However, I could not run an analysis to assess if the experiment was run long enough to cancel novelty effect and change aversion as date was not included in the dataset. Therefore, I recommend further analysis to determine the duration of the experiments and additional data on type of visitors (new or returning).<br>\n",
    "\n",
    "Overall, I recommend that the e-commerce company **should run the experiment longer before making a final decision**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

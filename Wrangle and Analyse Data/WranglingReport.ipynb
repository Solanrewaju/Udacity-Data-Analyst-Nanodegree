{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Report- Tweet Archives of @dog_rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<ul>\n",
    "<a href=\"#intro\">Introduction</a><br>\n",
    "<a href=\"#gather\">Gathering Data</a><br> \n",
    "<a href=\"#assess\">Assessing Data</a><br>\n",
    "<a href=\"#clean\">Cleaning Data</a><br>\n",
    "<a href=\"#reassess\">Reassess and Iterate</a><br>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## 1.0 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I wrangled data from three(3) sources to analyse and draw insights on the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates people's dogs with a humorous comment about the dog.\n",
    "<br> These ratings almost always have a denominator of 10. The numerators, though? Almost always greater than 10. 11/10, 12/10, 13/10, etc. Why? Because \"they're good dogs Brent.\" WeRateDogs has over 4 million followers and has received international media coverage.\n",
    "<br> One of the goals of this project is to 'wrangle WeRateDogs Twitter data to create interesting and trustworthy analyses and visualizations.' This document briefly describes my wrangling efforts on this project.\n",
    "\n",
    "Applying the methodology taught in this course, I performed the data wrangling process in three(3) steps. \n",
    "1. Gathering data\n",
    "2. Assessing data\n",
    "3. Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gather'></a>\n",
    "## Gathering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using python libraries (**pandas, requests, os, tweepy, json** etc.), I gathered data in 3 different file format from three sources which I stored in seperate files.\n",
    "1. **Enhanced Twitter Archive:** This **csv file** was shared internally by Udacity for this project. Therefore, it was *manually* downloaded into the project's folder. It contained basic tweet data for all 5,000+ of @WeRateDogs tweets as they stood on August 1, 2017.\n",
    "2. **Image Prediction:** The link to this **tsv file** was shared by Udacity. It includes data on the breeds of dogs (predicted) linked to the image and tweet ID. To ensure scalability and reproducibility, I downloaded this *programmatically* using the requests library.\n",
    "3. **Additional Data via the Twitter API:** Retweet count and favorite count are missing from the available datasets, this additonal data was gathered  by **querying Twitter's API** using *Tweepy*. First, I applied and set up my own Twitter application. For this, I choose to gather all available data for each tweet for later assessment on python. \n",
    "<br> I read the files into seperate tables named- `twitter_archive`, `image_predictions`and `additional_twitter_data`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assess'></a>\n",
    "## Assessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data gathering process completed, I moved on to the next step in the data wrangling process- **Assessing the Data**. Each table was assessed visually and programmatically for quality (content) and tidiness (structural) issues.\n",
    "- Visual Assessment: was done using both pandas and Microsoft Excel. I set rows and columns option so tables can be viewed without truncation.\n",
    "- Programmatic Assessment: Using several functions and methods in the pandas library (including- `.info()`, `.sample()`, `.isnull()`, `.sum()`, `.describe()`, `value_counts()` etc. \n",
    "\n",
    "<br> I systematically assessed each table column by column for completeness, validity, accuracy and consistency. Afterwhich, I assessed each table for tidiness issues. In assessing the data, I ensured that it alligned with project requirements such as including only original tweets (no retweets) that have images.\n",
    "\n",
    "<br>All issues identified were noted by type (quality/tidiness) and table. The following are **examples** of notes I made.\n",
    "<br> **Quality**\n",
    "- Twitter Archive: 78 Reply tweets are included  re:`in_reply_to_status_id`\n",
    "- Twitter Archive:`timestamp` in string format instead of datetime\n",
    "- Image prediction: 543 non-dog species such as cardigan, zebra, bookshop, web_site etc, returned.re:`p1_dog`=False\n",
    "<br> **Tidiness**\n",
    "- Twitter Archive: Stages of dog - doggo, pupper, puppy and floff(er) is in four columns\n",
    "- Image predictions: `p2`,`p2_conf`,`p2_dog`,`p3`,`p3_conf` and `p3_dog` are not applcable\n",
    "- Additional data: repeated columns in different data type including re: `id_str`, `in_reply_to_status_id_str` `in_reply_to_user_id_str` and `quoted_status_id_str`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "## Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this third step of the data wrangling process and to meet the project specification, I cleaned\n",
    "- 9+ quality issues\n",
    "- 5+ tidiness issues\n",
    "First, I created a copy of each data table. I choose to clean the issues documented in the table below which are relevant to my research questions.\n",
    "\n",
    "| s_no | issue | table| type |\n",
    "| --- | --- | --- | --- |\n",
    "| 1 | 78 Reply tweets are included re:`in_reply_to_status_id` | twitter archive | quality |\n",
    "| 2 | `timestamp` in string format instead of datetime | twitter archive | quality |\n",
    "| 3 | 181 Retweets are included re: `retweeted_status_id` | twitter archive | quality |\n",
    "| 4 | The source is in link which can be shorthened | twitter archive | quality |\n",
    "| 5 | missing expanded_urls | twitter archive | quality |\n",
    "| 6 | 'Outlier' `rating_numerator`  | twitter archive | quality |\n",
    "| 7 | 'Outlier' `rating_denominator` | twitter archive  | quality |\n",
    "| 8 | `rating_denominator` != 10 | twitter archive | quality |\n",
    "| 9 | 543 non-dog species re:`p1_dog`= False | image prediction | quality |\n",
    "| 10 |  Stages of dog - `doggo`, `pupper`, `puppy` and `floff`(er) is in four columns | twitter archive | tidiness |\n",
    "| 11 | reply columns (`in_reply_to_status_id` and `in_reply_to_user_id`) are not applicable | twitter archive | tidiness |\n",
    "| 12 | Retweet columns (`retweeted_status_id`, `retweeted_status_user_id` and `retweeted_status_timestamp` are not applicable| twitter archive | tidiness |\n",
    "| 13 | `rating_denominator` not applicable if all =10| twitter archive | tidiness \n",
    "| 14 | columns have non-descriptive names | image prediction | tidiness |\n",
    "| 15 | merge tables | all | tidiness |\n",
    "\n",
    "<br> Cleaning was done using the **define, code and test** approach. See below, an **example using issue #1** from the table above as an example.\n",
    "\n",
    "##### Quality 1 - 78 Reply tweets are included re: in_reply_to_status_id [archive]\n",
    "\n",
    "###### Define\n",
    "- Drop all rows with reply tweets where `in_reply_to_status_id` is notnull\n",
    "\n",
    "###### Code\n",
    "drop all reply tweets<br>\n",
    "`print(\"Before cleaning, reply tweets were: {}\".format(sum(archive_clean.in_reply_to_status_id.notnull())))\n",
    "archive_clean = archive_clean[archive_clean.in_reply_to_status_id.isna()]`\n",
    "###### Test\n",
    "confirm <br>\n",
    "`print(\"After cleaning, reply tweets were: {}\".format(sum(archive_clean.in_reply_to_status_id.notnull())))`\n",
    "\n",
    "> **Note:** While, I cleaned every issue sequentially, for issue #9 I observed that if I dropped the False prior to merging the tables, I end up with some tweets in the `master_clean` with rating for non-dog species example - https://twitter.com/dog_rates/status/666051853826850816  Therefore, I dropped affected rows after the tables were merged.\n",
    "\n",
    "<br> Cleaning was achieved using several functions and methods including `to_datetime`, `astype`, `notnull`, `drop`, `rename`, etc. At the end of this, a tidy master dataset named `master_clean` with all pieces of gathered data was created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='reassess'></a>\n",
    "\n",
    "## Reassess and Iterate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, after merging into a table, iterated the Assess and Clean steps to review the merged table. I noted the following which I used to assess and clean.\n",
    "- drop columns not relevant to analysis and duplicate columns\n",
    "- use descriptive header\n",
    "- check for nulls and missing values\n",
    "- check datatypes\n",
    "I used python and pandas libraries in this step. `master_clean` was then stored to file as `twitter_archive_master.csv`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
